{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Wikipedia Edits Data Pipeline - Solutions\n",
    "\n",
    "This notebook demonstrates a simple ETL pipeline that:\n",
    "1. Extracts data from the Wikipedia REST API\n",
    "2. Transforms it to JSON Lines format\n",
    "3. Uploads directly to S3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choose Your Username\n",
    "\n",
    "Pick a unique username (e.g., your name or initials) and use it consistently:\n",
    "\n",
    "- **S3 Bucket**: `<username>-wikidata` (e.g., `johndoe-wikidata`)\n",
    "- **Athena Database**: `<username>` (e.g., `johndoe`)\n",
    "- **Lambda**: Use the same `<username>-wikidata` bucket\n",
    "\n",
    "**Important:** No hyphens in database names! Use underscores if needed (e.g., `john_doe`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your username here - use it consistently across all resources\n",
    "USERNAME = \"zoltanctoth\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import json\n",
    "\n",
    "import boto3\n",
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract: Retrieve Data from Wikipedia API\n",
    "\n",
    "We use the Wikimedia Analytics API to fetch the most edited pages for a specific date. The API returns JSON with page titles and edit counts.\n",
    "\n",
    "**API Documentation:** https://doc.wikimedia.org/generated-data-platform/aqs/analytics-api/reference/edits.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try different dates to see how the data changes\n",
    "DATE_PARAM = \"2025-11-25\"\n",
    "\n",
    "date = datetime.datetime.strptime(DATE_PARAM, \"%Y-%m-%d\")\n",
    "\n",
    "# Construct the API URL\n",
    "url = f\"https://wikimedia.org/api/rest_v1/metrics/edited-pages/top-by-edits/en.wikipedia/user/content/{date.strftime('%Y/%m/%d')}\"\n",
    "print(f\"Requesting REST API URL: {url}\")\n",
    "\n",
    "# Make the API request\n",
    "wiki_server_response = requests.get(url, headers={\"User-Agent\": \"curl/7.68.0\"})\n",
    "wiki_response_status = wiki_server_response.status_code\n",
    "wiki_response_body = wiki_server_response.text\n",
    "\n",
    "print(f\"Wikipedia REST API Response body: {wiki_response_body[:500]}...\")\n",
    "print(f\"Wikipedia REST API Response Code: {wiki_response_status}\")\n",
    "\n",
    "# Validate response\n",
    "if wiki_response_status != 200:\n",
    "    raise Exception(f\"Received non-OK status code from Wiki Server: {wiki_response_status}\")\n",
    "print(f\"Successfully retrieved Wikipedia data, content-length: {len(wiki_response_body)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform: Process Raw Data into JSON Lines\n",
    "\n",
    "Convert the raw API response into a structured JSON Lines format suitable for analytics. Each line is a valid JSON object representing one page's edit statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the API response and extract top edits\n",
    "wiki_response_parsed = wiki_server_response.json()\n",
    "top_edits = wiki_response_parsed[\"items\"][0][\"results\"][0][\"top\"]\n",
    "\n",
    "# Transform to JSON Lines format\n",
    "current_time = datetime.datetime.now(datetime.timezone.utc)\n",
    "json_lines = \"\"\n",
    "for page in top_edits:\n",
    "    record = {\n",
    "        \"title\": page[\"page_title\"],\n",
    "        \"edits\": page[\"edits\"],\n",
    "        \"date\": date.strftime(\"%Y-%m-%d\"),\n",
    "        \"retrieved_at\": current_time.replace(tzinfo=None).isoformat(),\n",
    "    }\n",
    "    json_lines += json.dumps(record) + \"\\n\"\n",
    "\n",
    "print(f\"Transformed {len(top_edits)} records to JSON Lines\")\n",
    "print(f\"First few lines:\\n{json_lines[:500]}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 1: Create an S3 Bucket\n",
    "\n",
    "**Task:** Create an S3 bucket for the Wikipedia data pipeline.\n",
    "\n",
    "**Requirements:**\n",
    "- Bucket name: `<username>-wikidata` (use your USERNAME from above)\n",
    "- Create the bucket if it doesn't exist\n",
    "\n",
    "**Documentation:** [create_bucket](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/create_bucket.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "S3_WIKI_BUCKET = f\"{USERNAME}-wikidata\"\n",
    "s3 = boto3.client(\"s3\")\n",
    "\n",
    "# Lab 1 Solution: Create the bucket if it doesn't exist\n",
    "bucket_names = [bucket[\"Name\"] for bucket in s3.list_buckets()[\"Buckets\"]]\n",
    "if S3_WIKI_BUCKET not in bucket_names:\n",
    "    s3.create_bucket(\n",
    "        Bucket=S3_WIKI_BUCKET,\n",
    "        CreateBucketConfiguration={\"LocationConstraint\": \"eu-west-1\"},\n",
    "    )\n",
    "    print(f\"Created new bucket: {S3_WIKI_BUCKET}\")\n",
    "else:\n",
    "    print(f\"Using existing bucket: {S3_WIKI_BUCKET}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Lab 1\n",
    "assert USERNAME != \"<username>\", \"Please set your USERNAME at the top of the notebook\"\n",
    "assert S3_WIKI_BUCKET.endswith(\"-wikidata\"), \"Bucket name must end with '-wikidata'\"\n",
    "\n",
    "try:\n",
    "    s3.head_bucket(Bucket=S3_WIKI_BUCKET)\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} exists!\")\n",
    "except Exception as e:\n",
    "    print(f\"Bucket {S3_WIKI_BUCKET} not found: {e}\")\n",
    "    raise"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Lab 2: Upload JSON Lines to S3\n",
    "\n",
    "**Task:** Upload the `json_lines` data directly to S3 (no local file!).\n",
    "\n",
    "**Requirements:**\n",
    "- Use `s3.put_object()` to upload the data directly\n",
    "- Place the file under `raw-edits/` prefix in S3\n",
    "- File name: `raw-edits-YYYY-MM-DD.json` (use the date from `DATE_PARAM`)\n",
    "\n",
    "**Example S3 path:** `s3://johndoe-wikidata/raw-edits/raw-edits-2025-11-25.json`\n",
    "\n",
    "**Documentation:** [put_object](https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/s3/client/put_object.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lab 2 Solution: Upload json_lines directly to S3\n",
    "s3_key = f\"raw-edits/raw-edits-{date.strftime('%Y-%m-%d')}.json\"\n",
    "s3.put_object(\n",
    "    Bucket=S3_WIKI_BUCKET,\n",
    "    Key=s3_key,\n",
    "    Body=json_lines,\n",
    ")\n",
    "print(f\"Uploaded {len(top_edits)} records to s3://{S3_WIKI_BUCKET}/{s3_key}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test Lab 2\n",
    "expected_key = f\"raw-edits/raw-edits-{date.strftime('%Y-%m-%d')}.json\"\n",
    "try:\n",
    "    s3.head_object(Bucket=S3_WIKI_BUCKET, Key=expected_key)\n",
    "    print(f\"File uploaded successfully to s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "except Exception as e:\n",
    "    print(f\"File not found at s3://{S3_WIKI_BUCKET}/{expected_key}\")\n",
    "    raise"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
