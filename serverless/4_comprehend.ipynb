{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AWS Comprehend Tutorial\n",
    "\n",
    "This notebook demonstrates AWS Comprehend natural language processing capabilities including:\n",
    "- Language detection (single and multi-language)\n",
    "- Sentiment analysis\n",
    "- Named entity recognition\n",
    "- Key phrase extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Setup Environment\n",
    "\n",
    "Import required libraries and initialize the AWS Comprehend client."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries and set up our environment\n",
    "import pprint\n",
    "\n",
    "import boto3\n",
    "\n",
    "print(\"üìö Setting up the environment...\")\n",
    "\n",
    "# Initialize pretty printer for better output formatting\n",
    "pp = pprint.PrettyPrinter(indent=2)\n",
    "\n",
    "# Create Comprehend client\n",
    "comprehend = boto3.client(service_name=\"comprehend\", region_name=\"eu-west-1\")\n",
    "\n",
    "print(\"‚úÖ Environment setup complete!\")\n",
    "print(f\"üåç Using AWS region: {comprehend.meta.region_name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Single Language Detection\n",
    "\n",
    "Detect the dominant language in a simple English sentence and display confidence scores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate simple language detection\n",
    "print(\"üîç Testing single-language detection...\")\n",
    "\n",
    "text = \"This is a test sentence in English\"\n",
    "try:\n",
    "    response = comprehend.detect_dominant_language(Text=text)\n",
    "\n",
    "    print(\"\\nüìù Input text:\")\n",
    "    print(f'\"{text}\"')\n",
    "\n",
    "    print(\"\\nüåê Detected languages:\")\n",
    "    for language in response[\"Languages\"]:\n",
    "        print(f\"- {language['LanguageCode']}: {language['Score']:.2%} confidence\")\n",
    "\n",
    "    print(\"\\nüì¶ Raw response:\")\n",
    "    pp.pprint(response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-language Detection\n",
    "\n",
    "Test language detection on text containing multiple languages (German and French)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate multi-language detection\n",
    "print(\"üîç Testing multi-language detection...\")\n",
    "\n",
    "multilingual_text = \"A: Hallo, wie geht es Ihnen?\\nB: √áa va bien. Merci. Et toi?\"\n",
    "try:\n",
    "    response = comprehend.detect_dominant_language(Text=multilingual_text)\n",
    "\n",
    "    print(\"\\nüìù Input text:\")\n",
    "    print(f'\"{multilingual_text}\"')\n",
    "\n",
    "    print(\"\\nüåê Detected languages:\")\n",
    "    for language in response[\"Languages\"]:\n",
    "        print(f\"- {language['LanguageCode']}: {language['Score']:.2%} confidence\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Sentiment Analysis\n",
    "\n",
    "Analyze the sentiment of a short positive text and display sentiment scores for all categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate simple sentiment analysis\n",
    "print(\"Testing sentiment analysis with short text...\")\n",
    "\n",
    "text = \"Hey, I'm feeling great today!\"\n",
    "try:\n",
    "    response = comprehend.detect_sentiment(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "    print(\"\\nüìù Input text:\")\n",
    "    print(f'\"{text}\"')\n",
    "\n",
    "    print(\"\\nüí≠ Sentiment analysis:\")\n",
    "    print(f\"Overall sentiment: {response['Sentiment']}\")\n",
    "    print(\"\\nSentiment scores:\")\n",
    "    for sentiment, score in response[\"SentimentScore\"].items():\n",
    "        print(f\"- {sentiment}: {score:.2%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentiment Analysis on Longer Text\n",
    "\n",
    "Analyze sentiment of a longer movie description to show how Comprehend handles larger content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate sentiment analysis with longer text\n",
    "print(\"üòä Testing sentiment analysis with longer text...\")\n",
    "\n",
    "long_text = (\n",
    "    \"Chronicles the experiences of a formerly successful banker as a prisoner in the gloomy jailhouse \"\n",
    "    \"of Shawshank after being found guilty of a crime he did not commit. The film portrays the man's unique way \"\n",
    "    \"of dealing with his new, torturous life; along the way he befriends a number of fellow prisoners, most notably \"\n",
    "    \"a wise long-term inmate named Red.\"\n",
    ")\n",
    "\n",
    "try:\n",
    "    response = comprehend.detect_sentiment(Text=long_text, LanguageCode=\"en\")\n",
    "\n",
    "    print(\"\\nüìù Input text:\")\n",
    "    print(\"-\" * 40)\n",
    "    print(long_text)\n",
    "    print(\"-\" * 40)\n",
    "\n",
    "    print(\"\\nüí≠ Sentiment analysis:\")\n",
    "    print(f\"Overall sentiment: {response['Sentiment']}\")\n",
    "    print(\"\\nSentiment scores:\")\n",
    "    for sentiment, score in response[\"SentimentScore\"].items():\n",
    "        print(f\"- {sentiment}: {score:.2%}\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Named Entity Recognition\n",
    "\n",
    "Extract and identify named entities (people, organizations, locations) from text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate entity recognition\n",
    "print(\"üè∑Ô∏è  Testing named entity recognition...\")\n",
    "\n",
    "texts = [\n",
    "    \"Welcome to CEU's Data Engineering course run by Zoltan Toth.\",\n",
    "    \"Here we learn about the internet, AWS and Data Engineering.\",\n",
    "]\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîç Analyzing entities in texts:\")\n",
    "\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f'\\nüìù Text {i}: \"{text}\"')\n",
    "        response = comprehend.detect_entities(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "        if response[\"Entities\"]:\n",
    "            print(\"Found entities:\")\n",
    "            for entity in response[\"Entities\"]:\n",
    "                print(f\"- {entity['Text']} ({entity['Type']}): {entity['Score']:.2%} confidence\")\n",
    "        else:\n",
    "            print(\"No entities found.\")\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key Phrase Detection\n",
    "\n",
    "Identify and extract key phrases from text to understand the main topics and important concepts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Demonstrate key phrase detection\n",
    "print(\"üîë Testing key phrase detection...\")\n",
    "\n",
    "try:\n",
    "    print(\"\\nüîç Analyzing key phrases in texts:\")\n",
    "\n",
    "    for i, text in enumerate(texts, 1):\n",
    "        print(f'\\nüìù Text {i}: \"{text}\"')\n",
    "        response = comprehend.detect_key_phrases(Text=text, LanguageCode=\"en\")\n",
    "\n",
    "        if response[\"KeyPhrases\"]:\n",
    "            print(\"Found key phrases:\")\n",
    "            for phrase in response[\"KeyPhrases\"]:\n",
    "                print(f\"- {phrase['Text']}: {phrase['Score']:.2%} confidence\")\n",
    "        else:\n",
    "            print(\"No key phrases found.\")\n",
    "\n",
    "        print(\"\\nüì¶ Raw response:\")\n",
    "        pp.pprint(response)\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Error: {str(e)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
