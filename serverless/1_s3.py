# %%
# Import required libraries and set up our environment
# We'll use these throughout the tutorial to interact with AWS S3
import os
import pprint
import random
import string

import boto3

print("ğŸ“š Setting up the environment...")

# Initialize pretty printer for better output formatting
pp = pprint.PrettyPrinter(indent=2)

# Create S3 client using default credentials from AWS CLI
# boto3 will automatically use credentials from ~/.aws/credentials
s3 = boto3.client(
    "s3",
    region_name="eu-west-1",  # Ireland region
)

print("âœ… Environment setup complete!")
print(f"ğŸŒ Using AWS region: {s3.meta.region_name}")

# %%
# Let's first check what buckets already exist in your AWS account
# This helps us understand what resources we're starting with
print("ğŸ“‹ Listing all S3 buckets in your account...")
response = s3.list_buckets()

print("\nğŸ“¦ Raw response from AWS:")
pp.pprint(response)

print("\nğŸ“¦ Your current S3 buckets:")
if response["Buckets"]:
    for bucket in response["Buckets"]:
        print(f"- {bucket['Name']}")
else:
    print("No buckets found in your account")

print(f"\nâœ… Successfully retrieved {len(response['Buckets'])} buckets")

# %%
# Now we'll create a function to generate unique bucket names
# S3 bucket names must be globally unique across all AWS accounts
print("ğŸ”§ Setting up bucket name generator...")


def generate_bucket_name(base_name):
    """Generate a unique bucket name using base name and random digits"""
    random_part = "".join(random.choices(string.digits, k=3))
    return f"{base_name}-{random_part}"


# Generate a unique bucket name - replace 'add-your-name-here' with your name!
my_name = "add-your-name-here"  # TODO: Change this!
bucket_name = generate_bucket_name(my_name)

if my_name == "add-your-name-here":
    print("âŒ Remember to change 'add-your-name-here' to your actual name!")
else:
    print("âœ… Name generator ready")
    print(f"ğŸ“ Your generated bucket name: {bucket_name}")

# %%
# Create a new S3 bucket with our generated name
# We'll specify EU (Ireland) as our region
default_region = "eu-west-1"
print(f"ğŸš€ Creating new bucket: {bucket_name}")
print(f"ğŸŒ Region: {default_region}")

try:
    # Note: Bucket configuration is required for all regions except us-east-1
    bucket_configuration = {"LocationConstraint": default_region}
    response = s3.create_bucket(Bucket=bucket_name, CreateBucketConfiguration=bucket_configuration)

    print("\nğŸ“¦ AWS Response:")
    pp.pprint(response)

    if response["ResponseMetadata"]["HTTPStatusCode"] == 200:
        print(f"\nâœ… Success! Bucket {bucket_name} created in {default_region}")
except Exception as e:
    print(f"âŒ Error creating bucket: {str(e)}")

# %%
# Create a sample text file that we'll upload to S3
# This demonstrates creating and uploading content to our bucket
print("ğŸ“ Creating sample file...")

sample_content = """Hello from AWS S3!
This is a sample file created during the class.
You can modify this content to upload different text."""

try:
    with open("my_content.txt", "w") as file:
        file.write(sample_content)
    print("âœ… Sample file created locally")
    print(f"ğŸ“„ File contents ({len(sample_content)} characters):")
    print("-" * 40)
    print(sample_content)
    print("-" * 40)
except Exception as e:
    print(f"âŒ Error creating file: {str(e)}")

# %%
# Upload our file to S3
# This shows how to transfer local files to your S3 bucket
print(f"â¬†ï¸  Uploading file to bucket: {bucket_name}")

try:
    s3.upload_file("my_content.txt", bucket_name, "my_content.txt")
    print("âœ… Upload successful!")
    print(f"ğŸ“ File location: s3://{bucket_name}/my_content.txt")
    print(f"â„¹ï¸ Note: The https URL https://{bucket_name}.s3.eu-west-1.amazonaws.com/my_content.txt")
    print("   won't work directly because S3 objects are private by default!")
    print("   We'll generate a pre-signed URL later to access this file via HTTPS.")

    # Verify the upload by listing objects in the bucket
    objects = s3.list_objects_v2(Bucket=bucket_name)
    print("\nğŸ“¦ Current bucket contents:")
    for obj in objects.get("Contents", []):
        print(f"- {obj['Key']} ({obj['Size']} bytes)")
except Exception as e:
    print(f"âŒ Error uploading file: {str(e)}")

# %%
# Generate a pre-signed URL for temporary access to the file
# This allows others to download the file without AWS credentials
print("ğŸ”— Generating pre-signed URL...")

try:
    # Generate URL that expires in 1 hour (3600 seconds)
    presigned_url = s3.generate_presigned_url(
        "get_object", Params={"Bucket": bucket_name, "Key": "my_content.txt"}, ExpiresIn=3600
    )
    print("âœ… Pre-signed URL generated successfully!")
    print("\nğŸ“ URL Details:")
    print(f"- URL: {presigned_url}")
    print("- Expires in: 1 hour")
    print("- Anyone with this URL can download the file")
    print("â„¹ï¸  Note: You can adjust ExpiresIn for different durations")
except Exception as e:
    print(f"âŒ Error generating pre-signed URL: {str(e)}")

# %%
# Download the file we just uploaded
# This verifies our upload worked and shows how to retrieve files from S3
print("â¬‡ï¸  Downloading file from S3...")

try:
    s3.download_file(bucket_name, "my_content.txt", "my_content_downloaded.txt")
    print("âœ… Download successful!")

    # Display the contents to verify everything worked
    with open("my_content_downloaded.txt", "r") as file:
        downloaded_content = file.read()

    print("\nğŸ“„ Downloaded file contents:")
    print("-" * 40)
    print(downloaded_content)
    print("-" * 40)

    # Verify content matches
    if downloaded_content == sample_content:
        print("âœ… Content verification: Downloaded file matches original!")
    else:
        print("âŒ Content verification: Files don't match!")
except Exception as e:
    print(f"âŒ Error downloading file: {str(e)}")

# %%
# Clean up all resources we created
# This is important to avoid unnecessary AWS charges and maintain a clean workspace
print("ğŸ§¹ Starting cleanup process...")


def cleanup_resources():
    """Clean up all resources created during this tutorial"""
    cleanup_report = []

    try:
        # 1. Delete the object from S3
        print(f"ğŸ—‘ï¸  Deleting object from bucket {bucket_name}...")
        s3.delete_object(Bucket=bucket_name, Key="my_content.txt")
        cleanup_report.append("âœ… S3 object deleted")

        # 2. Delete the bucket
        print(f"ğŸ—‘ï¸  Deleting bucket {bucket_name}...")
        s3.delete_bucket(Bucket=bucket_name)
        cleanup_report.append("âœ… S3 bucket deleted")

        # 3. Delete local files
        local_files = ["my_content.txt", "my_content_downloaded.txt"]
        for file in local_files:
            if os.path.exists(file):
                os.remove(file)
                cleanup_report.append(f"âœ… Deleted local file: {file}")

        print("\nğŸ“‹ Cleanup Report:")
        for item in cleanup_report:
            print(item)
        print("\nâœ¨ All cleanup completed successfully!")

    except Exception as e:
        print(f"âŒ Error during cleanup: {str(e)}")
        print("âš ï¸  Some resources might need manual cleanup!")


# Execute the cleanup
cleanup_resources()

# Verify all buckets after cleanup
print("\nğŸ” Verifying cleanup - listing remaining buckets:")
final_buckets = s3.list_buckets()["Buckets"]
if not any(b["Name"] == bucket_name for b in final_buckets):
    print("âœ… Bucket successfully removed!")
else:
    print("âš ï¸  Bucket still exists - might need manual removal!")
